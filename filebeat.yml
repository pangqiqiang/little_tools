#=========================== Filebeat prospectors 文件探测器 =============================
filebeat.prospectors:　　#文件探测器

- input_type: log　　#探测类型，日志文件
  paths:            #路径
    - /data/w/www/*/logs/request.log　　#注意，通配符*的存在使得相同目录结构的工程日志都会被收集到。
  #json.keys_under_root: true 若收取日志格式为json的log，请开启此配置
  document_type: request                #日志类型，也就是elastic索引的type，请见文章随后详细解释1
  fields:
    topic: log_common                   #增加fields.topic:"application_log"字段，用于kafka的多topic配置。

- input_type: log　
  paths:　
    - /data/w/www/*/logs/dubbo-access-consumer.log 
  multiline.pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}\ [0-9]{2}:[0-9]{2}:[0-9]{2}' #对于多行的的日志处理，请见文章随后的详细解释2
  multiline.negate: true
  multiline.match: after
  document_type: dubbo_consumer 
    topic: application_log　　
  

#----------------------------- kafka output --------------------------------
output.kafka:　　#输出到kafka
  hosts: ["kafka4.dp.data.cn1.wormpex.com:9092", "kafka5.dp.data.cn1.wormpex.com:9092", "kafka6.dp.data.cn1.wormpex.com:9092"] #kafka-broker地址
  topic: '%{[fields.topic]}' #输出到哪个topic（就是日志探测哪里定义的fields.topic，利用变量自动发送到不同topic）
  partition.round_robin:
    reachable_only: false
  required_acks: 1
  compression: gzip
  max_message_bytes: 100000000 #单条日志大小不超过10MB（笔者公司日志出现过单条好几MB的情况。。。）
#----------------------------- Logstash output --------------------------------
#output.logstash:
#  # The Logstash hosts
#  hosts: ["logstash1.ops.sys.cn1.wormpex.com:5044"] #logstash需要开启input beta插件，启动监听5044端口